# -*- coding: utf-8 -*-
import os
import io
import re
import pdfplumber
import pytesseract
from pdf2image import convert_from_bytes
import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
from dotenv import load_dotenv
import anthropic
import streamlit as st

# ===============================
# 1. Claude API
# ===============================
load_dotenv()
CLAUDE_API_KEY = os.getenv("ANTHROPIC_API_KEY")
client = anthropic.Anthropic(api_key=CLAUDE_API_KEY)

# ===============================
# 2. PDF â†’ í…ìŠ¤íŠ¸ ì¶”ì¶œ (pdfplumber + OCR)
# ===============================
def extract_pdf_to_text(file):
    text = ""
    pdf_bytes = file.read()
    with pdfplumber.open(io.BytesIO(pdf_bytes)) as pdf:
        for i, page in enumerate(pdf.pages):
            page_text = page.extract_text()
            if page_text and page_text.strip():
                text += page_text + "\n"
            else:
                # OCR fallback
                images = convert_from_bytes(pdf_bytes, first_page=i+1, last_page=i+1)
                for img in images:
                    ocr_text = pytesseract.image_to_string(img, lang="kor+eng")
                    text += ocr_text + "\n"
    # ë¡œê·¸ ì¶œë ¥: í…ìŠ¤íŠ¸ ê¸¸ì´ì™€ í‚¤ì›Œë“œ ìœ ë¬´
    st.write(f"[DEBUG] ì¶”ì¶œ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}")
    if "ê±´ì „ì§€" in text:
        st.write("ğŸ” 'ê±´ì „ì§€' í‚¤ì›Œë“œê°€ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ì— í¬í•¨ë¨!")
    return text

# ===============================
# 3. í…ìŠ¤íŠ¸ ì²­í¬ ë¶„í• 
# ===============================
def chunk_text(text, chunk_size=300):
    words = text.split()
    return [" ".join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]

# ===============================
# 4. ChromaDB ì¸ë±ìŠ¤ ìƒì„±
# ===============================
def build_chroma_index(pdf_files, embedding_model):
    chroma_client = chromadb.Client(Settings())
    # ê¸°ì¡´ manual ì»¬ë ‰ì…˜ ì‚­ì œ
    for c in chroma_client.list_collections():
        if c.name == "manual":
            chroma_client.delete_collection("manual")
    collection = chroma_client.create_collection("manual")

    for pdf in pdf_files:
        text = extract_pdf_to_text(pdf)
        if not text.strip():
            st.warning(f"{pdf.name}ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨")
            continue
        chunks = chunk_text(text)
        embeddings = embedding_model.encode(chunks, show_progress_bar=False).tolist()
        for i, (chunk, emb) in enumerate(zip(chunks, embeddings)):
            collection.add(
                ids=[f"{pdf.name}_{i}"],
                embeddings=[emb],
                documents=[chunk]
            )
    return collection

# ===============================
# 5. ê²€ìƒ‰ (ì§ˆë¬¸ í‚¤ì›Œë“œ ê¸°ë°˜ + ë²¡í„° í˜¼í•©)
# ===============================
def keyword_filter(question, docs):
    """ê°„ë‹¨ í‚¤ì›Œë“œ ê¸°ë°˜ í•„í„°ë§"""
    keywords = re.findall(r"[ê°€-í£A-Za-z0-9]+", question)
    hits = [d for d in docs if any(k in d for k in keywords)]
    return hits

def search_context(question, collection, embedding_model, top_k=3):
    q_emb = embedding_model.encode([question]).tolist()
    results = collection.query(query_embeddings=q_emb, n_results=top_k*2)  # ì¡°ê¸ˆ ë” ë„“ê²Œ ê²€ìƒ‰
    docs = results["documents"][0]
    # í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ê°€ í•„í„°ë§
    keyword_hits = keyword_filter(question, docs)
    final_docs = keyword_hits if keyword_hits else docs[:top_k]
    return "\n---\n".join(final_docs)

# ===============================
# 6. Claude ì‘ë‹µ
# ===============================
def ask_claude(question, collection, embedding_model):
    context = search_context(question, collection, embedding_model)
    prompt = f"""
ë„ˆëŠ” ìë™ì°¨ ì„¤ëª…ì„œ ì „ë¬¸ê°€ë‹¤.
ì•„ë˜ëŠ” Owner's Manualì—ì„œ ê°€ì ¸ì˜¨ ê´€ë ¨ ë‚´ìš©ì´ë‹¤:
--------------------
{context}
--------------------
ì§ˆë¬¸: {question}

ì„¤ëª…ì„œ ë‚´ìš© ê¸°ë°˜ìœ¼ë¡œë§Œ ë‹µë³€í•˜ë˜, ë‚´ìš©ì´ ë¶€ì¡±í•˜ë©´
'ì„¤ëª…ì„œì— ì§ì ‘ì ì¸ ì–¸ê¸‰ì€ ì—†ì§€ë§Œ ìœ ì‚¬í•œ ë‚´ìš©ì´ ìˆìŠµë‹ˆë‹¤'ë¼ê³  ë§í•˜ê³ ,
ê°€ëŠ¥í•œ ê´€ë ¨ ì •ë³´ë¥¼ ìš”ì•½í•´ì¤˜.
"""
    response = client.messages.create(
        model="claude-3-5-sonnet-20240620",
        max_tokens=600,
        messages=[{"role": "user", "content": prompt}]
    )
    return response.content[0].text.strip()

# ===============================
# 7. Streamlit UI
# ===============================
def main():
    st.title("Claude + Owner's Manual (ì •í™•ë„ ê°•í™” ë²„ì „)")

    uploaded_files = st.file_uploader("PDF íŒŒì¼ ì—…ë¡œë“œ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)", type="pdf", accept_multiple_files=True)
    question = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")

    if st.button("ì§ˆë¬¸í•˜ê¸°"):
        if not uploaded_files:
            st.warning("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
            return

        with st.spinner("ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘..."):
            embedding_model = SentenceTransformer("paraphrase-MiniLM-L3-v2")

        with st.spinner("PDF ë¶„ì„ ë° ë²¡í„° DB ìƒì„± ì¤‘..."):
            collection = build_chroma_index(uploaded_files, embedding_model)

        with st.spinner("Claude ì‘ë‹µ ìƒì„± ì¤‘..."):
            answer = ask_claude(question, collection, embedding_model)

        st.subheader("Claude ì‘ë‹µ")
        st.write(answer)

if __name__ == "__main__":
    main()
